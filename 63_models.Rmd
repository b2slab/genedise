---
title: "Models on performance metrics"
author: "Sergio Picart-Armada"
date: "February 28, 2018"
output: html_document
---

```{r setup, include=FALSE}
# Show the code, but suppress messages and warnings
# otherwise document gets too long
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Getting started

```{r}
# Data handling
library(plyr)
library(dplyr)
library(tidyr)
library(magrittr)

# least squares means
library(lsmeans)
library(multcomp)

# generate latex tables
library(knitr)
library(kableExtra)

# plotting
library(ggplot2)


# parallel computing (contrasts are slow)
library(doMC)
doMC::registerDoMC(cores = parallel::detectCores()) 

df_nets <- plyr::ldply(
  list(string = "20", omnipath = "40"), 
  function(net_prefix) {
    # have all config variables in a different env
    config <- new.env(parent = globalenv())
    source(paste0(net_prefix, "_config.R"), local = config)
    
    # load all the metrics csv files
    list_files <- list.files(
      config$dir_performance, pattern = "^metrics.+"
    )
    
    df_models <- plyr::ldply(
      setNames(list_files, list_files), 
      function(file_name) {
        read.table(
          paste0(config$dir_performance, "/", file_name), 
          header = TRUE 
        )
      }, 
      .id = "cv_scheme"
    ) %>% mutate(
      cv_scheme = gsub("(metrics_cvscheme_)(.+)(\\.csv)", "\\2", cv_scheme)
    )
    
    df_models
  }, 
  .id = "network"
)

# own config files
config <- new.env(parent = globalenv())
source("60_config.R", local = config)
```

# Data formatting

```{r}
list_models <- setNames(
  c("binomial", "binomial", "binomial", "binomial", "poisson", "poisson"), 
  c("auroc", "partial_auroc_0.90", "partial_auroc_0.95", "auprc", "top_20_hits", "top_100_hits")
)

levels_method <- c(
  "pr", "randomraw", "random", "EGAD", 
  "association_score.datatypes.affected_pathway", 
  "association_score.datatypes.animal_model", 
  "association_score.datatypes.genetic_association", 
  "association_score.datatypes.literature", 
  "association_score.datatypes.rna_expression", 
  "association_score.datatypes.somatic_mutation", 
  "ppr", "raw", "gm", "mc", "z", 
  "knn", "wsld", 
  "COSNet", "bagsvm", "rf", "svm")
# only these methods will play in the models
methods_models <- c(
  "pr", "randomraw", "random", "EGAD", 
  "ppr", "raw", "gm", "mc", "z", 
  "knn", "wsld", 
  "COSNet", "bagsvm", "rf", "svm"
)
streams_abbrev <- c(
  "association_score.datatypes.affected_pathway" = "s:ap", 
  "association_score.datatypes.animal_model" = "s:am", 
  "association_score.datatypes.genetic_association" = "s:ga", 
  "association_score.datatypes.literature" = "s:l", 
  "association_score.datatypes.rna_expression" = "s:re", 
  "association_score.datatypes.somatic_mutation" = "s:sm"
)
levels_cv_scheme <- c("classic", "block", "representative")
levels_network <- c("string", "omnipath")

df_nets$method <- factor(df_nets$method, levels_method)
df_nets$cv_scheme <- factor(df_nets$cv_scheme, levels_cv_scheme)

# temporary lines (because not everything is run)
# df_models <- filter(
#   df_models, 
#   as.character(disease) <= "type I diabetes mellitus")
# diseases <- unique(df_models$disease) %>% as.factor
```

```{r}
# Average the folds of each repetition
# treat reference streams as a different data input
df_nets_avg <- mutate(
  df_nets, 
  split_cv = as.factor(gsub("(^Rep\\d+)(\\..+$)", "\\1", split_cv)), 
  input_type = as.factor(ifelse(method %in% names(streams_abbrev), 
                                "stream", as.character(input_type)))) %>% 
  group_by(network, cv_scheme, disease, input_type, split_cv, method) %>% 
  summarise_all(funs(mean))
```


# Models 

## Logistic and poisson models

```{r}
list_strat <- list(
  none = NULL, 
  cv_scheme = "cv_scheme", 
  network = "network", 
  cv_scheme_network = c("cv_scheme", "network")
)

# generate output folders
plyr::l_ply(
  levels(df_nets_avg$input_type), 
  function(input) {
    dir.create(paste0(config$dir_models, "/", input))
  }
)
```


```{r}
# WATCHOUT: do not mix input types!
plyr::a_ply(
  expand.grid(metric = names(list_models), 
              input_type = levels(df_nets_avg$input_type), 
              stringsAsFactors = FALSE), 
  1, 
  function(vars) {
    # browser()
    options(max.print = 2000, width = 1000)
    
    model_famname <- list_models[vars$metric]
    model_fam <- switch(
      model_famname, 
      "binomial" = quasibinomial(link = "logit"),
      "poisson" = quasipoisson(link = "log"))
    
    df_current <- filter(df_nets_avg, input_type == vars$input_type)
    file_prefix <- paste(c(model_famname, vars$metric), collapse = "_")
    spit_prefix <- "lsmeans_split:"
    
    # adjust models subsetting by input_type and using 
    # the given metric as response
    # 
    ###### Additive model ###### 
    mod <- glm(
      as.formula(paste0(vars$metric, " ~ method + disease + cv_scheme + network")), 
      data = df_current, 
      family = model_fam)
    
    mod_dir <- paste0(config$dir_models, "/", vars$input_type, "/additive/")
    dir.create(path = mod_dir)
    
    # write model summary
    writeLines(
      capture.output(summary(mod)),
      con = paste0(mod_dir, "/", file_prefix, "_model.txt")
    )
    # browser()
    # write predictions based on several grouping factors
    # (e.g. performance per disease vs performance averaged in all diseases )
    plyr::llply(
      list_strat,
      function(variables) {
        # browser()
        variables_name <- paste(variables, collapse = ",")
        predictions <- lsmeans::lsmeans(
          mod, specs = "method",
          by = variables,
          type = "response") %>% summary
        # write summary
        writeLines(
          capture.output(print(predictions)),
          con = paste0(mod_dir, "/", file_prefix, ";", spit_prefix,
                       variables_name, ".txt")
        )
        # write latex table
        write.csv(
          predictions, row.names = FALSE, 
          file = paste0(mod_dir, "/", file_prefix, ";", spit_prefix,
                       variables_name, ".csv")
        )
      }
    )
    
    # browser()
    # compute contrasts between methods
    mod_glht <- multcomp::glht(
      mod, 
      linfct = multcomp::mcp(method = "Tukey"))
    
    # model diagnostic plots
    png(filename = paste0(mod_dir, "/", file_prefix, "_diagnostics.png"), 
        width = 20, height = 20, units = "cm", res = 300)
    layout(matrix(1:4, ncol = 2))
    plot(mod, pch = ".", ask = FALSE)
    layout(1)
    dev.off()
    
    mod_confint <- summary(mod_glht)
    writeLines(
      capture.output(print(mod_confint)), 
      con = paste0(mod_dir, "/", file_prefix, "_contrasts_method.txt")
    )

    # Plot contrasts and estimates
    cols <- names(mod_confint$test$coefficients) %>% 
      strsplit(split = " - ") %>% plyr::ldply(
      function(x) c(row = x[1], col = x[2])
    ) 
    cols$row <- factor(cols$row, levels_method)
    cols$col <- factor(cols$col, levels_method)
    cols$estimate <- mod_confint$test$coefficients 
    cols$pvalue <- mod_confint$test$pvalues
    
    e.cor <- reshape2::acast(cols, row~col, value.var = "estimate", fill = 0)
    p.cor <- reshape2::acast(cols, row~col, value.var = "pvalue", fill = 0)
    
    png(filename = paste0(mod_dir, "/", file_prefix, "_contrasts_method.png"),  
        width = 1200, height = 1200)
    corrplot::corrplot(
      corr = e.cor, method = "color", type = "lower", 
      addCoef.col = "black", 
      p.mat = p.cor, diag = TRUE, is.corr = FALSE)
    dev.off()
    
    ###### Other models ###### 
  }, 
  .progress = "text", 
  .parallel = TRUE
)
```

## Tables in LaTeX

```{r}
# take only main metrics and stratification
# additive models only

# stats to focus on
list_strat_main <- c("cv_scheme", "network")  
# Models to include in the main text tables with number of digits
list_metrics <- c("auroc" = 3, "partial_auroc_0.90" = 3, 
                  "partial_auroc_0.95" = 3, "auprc" = 3, 
                  "top_20_hits" = 2, "top_100_hits" = 2)
list_metrics_main <- c("auroc", "auprc", "top_20_hits")
# Columns to include 
list_columns_main <- c("asymp.LCL", "asymp.UCL")

plyr::l_ply(
  levels(df_nets_avg$input_type), 
  function(input) {
    dir_input <- paste0(config$dir_models, "/", input, "/additive/")
    df_out <- plyr::ldply(
      names(list_metrics), 
      function(metric) {
        # browser()
        # read formatted table
        file_name <- paste0(dir_input, list_models[metric], "_", 
                            metric, ";", "lsmeans_split:", 
                            paste(list_strat_main, collapse = ","), ".csv")
        df <- read.csv(file_name, header = TRUE)
        
        # Format confidence interval
        digits <- list_metrics[metric]
        df$metric <- metric
        df$col_ci <- paste0(
          "[", 
          format(df$asymp.LCL, digits = 0, nsmall = digits), 
          ", ", 
          format(df$asymp.UCL, digits = 0, nsmall = digits), 
          "]")
        df[c(list_strat_main, "metric", "method", "col_ci")]
      }, 
      .id = "metric") %>% 
      mutate(metric = factor(metric, names(list_metrics)), 
             method = factor(method, levels_method), 
             cv_scheme = factor(cv_scheme, levels_cv_scheme), 
             network = factor(network, levels_network))
    # browser()
    # cast the data frame so that network+cvscheme define the columns
    # need to cast through data.table to be able to choose the separator
    df_out_cast <- data.table::dcast(
      data.table::setDT(df_out), metric + method ~ network + cv_scheme, 
      value.var = "col_ci", sep = ".") 
    
    # kable accepts escape=FALSE in case math mode is to be entered manually, adding $s to the cells
    # 
    # only metrics in the main body
    tex <- knitr::kable(filter(df_out_cast, metric %in% list_metrics_main), 
                        format = "latex", booktabs = TRUE, escape = TRUE) %>% 
      kable_styling(latex_options = c("striped", "scale_down")) %>% 
      collapse_rows(columns = 1:2, latex_hline = "major") %>% 
      add_header_above(c(" " = 2, "STRING" = 3, "OmniPath" = 3)) 
    writeLines(tex, con = paste0(dir_input, "tex_main_metrics.tex"))
    
    # all the metrics
    tex <- knitr::kable(df_out_cast, format = "latex", booktabs = TRUE, escape = TRUE) %>% 
      kable_styling(latex_options = c("striped", "scale_down")) %>% 
      collapse_rows(columns = 1:2, latex_hline = "major") %>% 
      add_header_above(c(" " = 2, "STRING" = 3, "OmniPath" = 3)) 
    writeLines(tex, con = paste0(dir_input, "tex_all_metrics.tex"))
  }
)
```

# Reproducibility

```{r}
out <- capture.output(sessionInfo())
writeLines(out, con = paste0(config$dir_metadata, "/63_sessionInfo.txt"))
```
